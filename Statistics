{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOE9jLN08iZZ/1it9W0wEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swati642/Python-Assignment-1/blob/main/Statistics\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is hypothesis testing in statistics*\n",
        "Hypothesis testing is a statistical method to determine if there is enough evidence to reject a null hypothesis (H₀) in favor of an alternative hypothesis (H₁)."
      ],
      "metadata": {
        "id": "WZpaJnTP4Whi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What is the null hypothesis, and how does it differ from the alternative hypothesis*\n",
        "Ans. The null hypothesis (H₀) is a statement that assumes no effect, no difference, or no relationship between variables. It represents the status quo or a claim to be tested.\n",
        "\n",
        "The alternative hypothesis (H₁ or Ha) is the opposite of H₀ and suggests that there is an effect, difference, or relationship."
      ],
      "metadata": {
        "id": "f9Swu7DS4hDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the significance level in hypothesis testing, and why is it important*\n",
        "Ans. he significance level (α) in hypothesis testing represents the probability of making a Type I error, which is rejecting the null hypothesis when it is actually true. It acts as a threshold to determine whether the observed data is statistically significant. Common values for α are 0.05 (5%) or 0.01 (1%), meaning there is a 5% or 1% risk of incorrectly rejecting H₀. A lower α reduces the chances of false positives but increases the risk of missing a true effect (Type II error). If the p-value is less than or equal to α, we reject the null hypothesis; otherwise, we fail to reject it."
      ],
      "metadata": {
        "id": "gXpt7p_s4nvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does a P-value represent in hypothesis testing\n",
        "Ans. A P-value in hypothesis testing represents the probability of obtaining results as extreme as, or more extreme than, the observed data, assuming the null hypothesis (H₀) is true. It helps determine statistical significance. A lower P-value (typically ≤ 0.05) suggests strong evidence against H₀, leading to its rejection. If the P-value is high, it means the data does not provide enough evidence to reject H₀."
      ],
      "metadata": {
        "id": "2I92w_Ed40xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you interpret the P-value in hypothesis testing\n",
        "Ans. The P-value in hypothesis testing indicates the strength of evidence against the null hypothesis (H₀). A low P-value (≤ α, usually 0.05 or 0.01) suggests strong evidence against H₀, leading to its rejection. A high P-value (> α) means there is insufficient evidence to reject H₀, implying the observed data could have occurred by chance. However, a high P-value does not prove H₀ is true; it only indicates a lack of strong evidence against it."
      ],
      "metadata": {
        "id": "vP3oES_D4_Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are Type 1 and Type 2 errors in hypothesis testing\n",
        "Ans. In hypothesis testing, a Type I error occurs when the null hypothesis (H₀) is wrongly rejected, even though it is true. This is also called a false positive and is controlled by the significance level (α).\n",
        "\n",
        "A Type II error happens when the null hypothesis (H₀) is not rejected, even though it is false. This is a false negative and is influenced by factors like sample size and statistical power (β).\n",
        "\n",
        "Simply put, Type I error means detecting an effect that isn’t there, while Type II error means missing an effect that actually exists."
      ],
      "metadata": {
        "id": "-Jd4U1xG5KDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
        "Ans. A one-tailed test checks for an effect in only one direction (either greater than or less than a certain value). It is used when we expect a specific directional change.\n",
        "\n",
        "A two-tailed test checks for an effect in both directions (greater than or less than). It is used when we want to test for any significant difference, regardless of direction.\n",
        "\n",
        "For example, if testing whether a new drug increases effectiveness:\n",
        "\n",
        "One-tailed test: \"The drug is more effective than the current one.\"\n",
        "Two-tailed test: \"The drug has a different effect (either more or less effective) than the current one.\""
      ],
      "metadata": {
        "id": "Lqx81Fqt6PNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the Z-test, and when is it used in hypothesis testing\n",
        "Ans. A Z-test is a statistical test used to determine whether two population means are different when the population variance is known and the sample size is large (n ≥ 30). It follows a normal distribution (Z-distribution).\n",
        "\n",
        "It is used when:\n",
        "\n",
        "The data is normally distributed.\n",
        "The sample size is large (n ≥ 30).\n",
        "The population variance is known."
      ],
      "metadata": {
        "id": "Iz1IdNKA6XOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing*\n",
        "Ans . The Z-score measures how many standard deviations an observed value or sample mean is from the population mean. It helps determine the P-value and whether to reject the null hypothesis (H₀) based on a predefined significance level (α). A higher absolute Z-score indicates stronger evidence against H₀.\n",
        " Z score formula ,  Z = (X̄ - μ) / (σ / √n)\n",
        " X = observed value\n",
        "X̄ = sample mean\n",
        "μ = population mean\n",
        "σ = population standard deviation\n",
        "n = sample size"
      ],
      "metadata": {
        "id": "bTbCJnJh6eN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the T-distribution, and when should it be used instead of the normal distribution*\n",
        "Ans The T-distribution (Student’s t-distribution) is a probability distribution used in hypothesis testing when the sample size is small (n < 30) and the population standard deviation (σ) is unknown. It is similar to the normal distribution but has heavier tails, meaning it accounts for more variability in small samples.\n",
        "\n",
        "It should be used instead of the normal distribution when:\n",
        "\n",
        "The sample size is small (n < 30).\n",
        "The population standard deviation (σ) is unknown.\n",
        "The data is approximately normally distributed.\n",
        "As the sample size increases, the T-distribution approaches the normal distribution"
      ],
      "metadata": {
        "id": "adiXBv137Y0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is the difference between a Z-test and a T-test\n",
        "Ans . A Z-test is used when the sample size is large (n ≥ 30) and the population standard deviation (σ) is known. It follows the normal distribution.\n",
        "\n",
        "A T-test is used when the sample size is small (n < 30) and the population standard deviation is unknown. It follows the T-distribution, which has heavier tails to account for variability in small samples.\n",
        "\n",
        "In short, use a Z-test for large samples with known σ and a T-test for small samples with unknown σ."
      ],
      "metadata": {
        "id": "DdBcKhQ37jEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the T-test, and how is it used in hypothesis testing\n",
        "Ans. A T-test is a statistical test used to compare the means of one or two groups when the sample size is small (n < 30) and the population standard deviation (σ) is unknown. It follows the T-distribution.\n",
        "\n",
        "How It Is Used in Hypothesis Testing:\n",
        "State the hypotheses:\n",
        "\n",
        "Null hypothesis (H₀): No difference between means.\n",
        "Alternative hypothesis (H₁): A significant difference exists.\n",
        "Choose the significance level (α), typically 0.05 or 0.01.\n",
        "\n",
        "Calculate the T-statistic using the formula:\n",
        "\n",
        "plaintext\n",
        "Copy\n",
        "Edit\n",
        "t = (X̄ - μ) / (s / √n)\n",
        "Where:\n",
        "\n",
        "X̄ = sample mean\n",
        "μ = population mean (or mean of another sample)\n",
        "s = sample standard deviation\n",
        "n = sample size\n",
        "Compare the T-statistic to the critical T-value from the T-distribution table or use the P-value approach.\n",
        "\n",
        "Decision Rule:\n",
        "\n",
        "If |t| is greater than the critical value or P-value ≤ α, reject H₀.\n",
        "Otherwise, fail to reject H₀.\n",
        "Types of T-tests:\n",
        "One-sample T-test: Compares a sample mean to a known population mean.\n",
        "Independent (Two-sample) T-test: Compares means of two independent groups.\n",
        "Paired T-test: Compares means of the same group before and after a treatment."
      ],
      "metadata": {
        "id": "swBqvbzI7p_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the relationship between Z-test and T-test in hypothesis testing\n",
        "Ans The Z-test and T-test are both statistical methods used in hypothesis testing to compare means, but they differ in when they are used.\n",
        "\n",
        "The relationship between them lies in the sample size and population standard deviation (σ):\n",
        "\n",
        "The Z-test is used when the sample size is large (n ≥ 30) and the population standard deviation is known. It follows the normal distribution.\n",
        "The T-test is used when the sample size is small (n < 30) and the population standard deviation is unknown. It follows the T-distribution, which has heavier tails to account for more variability.\n",
        "As the sample size increases, the T-distribution approaches the normal distribution, meaning the T-test results become similar to the Z-test. Thus, for large samples, both tests give nearly identical results."
      ],
      "metadata": {
        "id": "Ln2Jw0Qu71n5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is a confidence interval, and how is it used to interpret statistical results\n",
        "Ans. A confidence interval (CI) is a range of values that estimates an unknown population parameter with a certain level of confidence. It is used to measure the reliability of an estimate in statistics.\n",
        "\n",
        "For example, a 95% confidence interval means that if we repeat the study multiple times, 95% of the calculated intervals will contain the true population parameter\n",
        "CI = X̄ ± (Z* × σ / √n)   (when σ is known, use Z-distribution)\n",
        "CI = X̄ ± (t* × s / √n)   (when σ is unknown, use T-distribution)\n",
        "X̄ = sample mean\n",
        "σ = population standard deviation\n",
        "s = sample standard deviation\n",
        "n = sample size\n",
        "Z* or t* = critical value from Z or T-distribution"
      ],
      "metadata": {
        "id": "71BzrDAm8bZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "smy9u_Mj5Ejl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the margin of error, and how does it affect the confidence interval\n",
        "Ans. The margin of error (ME) represents the uncertainty in an estimate and determines the width of a confidence interval (CI). It is calculated as:\n",
        "\n",
        "ME = Z* × (σ / √n)   (if σ is known)  \n",
        "ME = t* × (s / √n)   (if σ is unknown)  \n",
        "A larger ME results in a wider CI (more uncertainty), while a smaller ME gives a narrower CI (more precision). ME decreases with a larger sample size (n) and increases with a higher confidence level"
      ],
      "metadata": {
        "id": "ACng7c2F8omV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How is Bayes' Theorem used in statistics, and what is its significance\n",
        "Ans. Bayes' Theorem is used in statistics to update the probability of an event based on new evidence. It is given by:\n",
        "\n",
        "P(A | B) = [P(B | A) × P(A)] / P(B)\n",
        "Where:\n",
        "\n",
        "P(A | B): Probability of event A given B (posterior probability)\n",
        "P(B | A): Probability of event B given A (likelihood)\n",
        "P(A): Prior probability of A\n",
        "P(B): Total probability of B\n",
        "Significance:\n",
        "Helps in updating beliefs with new data.\n",
        "Used in machine learning, spam filtering, medical diagnosis, and risk assessment.\n",
        "Forms the basis of Bayesian inference, which is widely used in statistical modeling"
      ],
      "metadata": {
        "id": "qRVMIfsN9EF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is the Chi-square distribution, and when is it used\n",
        "Ans. The Chi-square (χ²) distribution is a probability distribution used in hypothesis testing for categorical data. It is asymmetric and depends on degrees of freedom (df).\n",
        "\n",
        "When is it Used?\n",
        "Chi-square goodness-of-fit test: Checks if observed data matches an expected distribution.\n",
        "Chi-square test for independence: Determines if two categorical variables are related.\n",
        "Chi-square test for variance: Tests if a population variance equals a specified value.\n",
        "It is used when data is categorical, sample sizes are large, and expected frequencies in each category are sufficient (typically ≥ 5)."
      ],
      "metadata": {
        "id": "2Fe56OvS9PFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the Chi-square goodness of fit test, and how is it applied\n",
        "Ans. The Chi-square goodness-of-fit test determines whether an observed categorical data distribution differs significantly from an expected distribution. It checks if data follows a hypothesized pattern.\n",
        "\n",
        "Formula:\n",
        "χ² = Σ [(O - E)² / E]\n",
        "Where:\n",
        "\n",
        "O = Observed frequency\n",
        "E = Expected frequency\n",
        "Application Steps:\n",
        "State Hypotheses:\n",
        "H₀ (Null Hypothesis): Observed data follows the expected distribution.\n",
        "H₁ (Alternative Hypothesis): Observed data does not follow the expected distribution.\n",
        "Calculate Expected Frequencies based on theoretical assumptions.\n",
        "Compute Chi-square Statistic (χ²) using the formula.\n",
        "Compare χ² to Critical Value from the Chi-square table (based on significance level and degrees of freedom).\n",
        "Decision Rule:\n",
        "If χ² is greater than the critical value or P-value ≤ α, reject H₀.\n",
        "Otherwise, fail to reject H₀."
      ],
      "metadata": {
        "id": "cUJ1K0Dl-Hzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is the F-distribution, and when is it used in hypothesis testing\n",
        "Ans. The F-distribution is a probability distribution that appears in hypothesis testing when comparing the variances of two populations. It is right-skewed and depends on two degrees of freedom, one for the numerator and one for the denominator. This distribution is primarily used in statistical tests such as ANOVA, where it helps determine whether the means of multiple groups are significantly different by analyzing their variance. It is also used in the F-test for comparing the equality of variances between two populations and in regression analysis to assess the overall significance of a model. Since the F-distribution is always positive, it is particularly useful in situations where variance ratios are analyzed."
      ],
      "metadata": {
        "id": "RxxWz0gf_sk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an ANOVA test, and what are its assumptions\n",
        "Ans. The ANOVA (Analysis of Variance) test is a statistical method used to determine whether there are significant differences between the means of three or more independent groups. It compares variance within groups to variance between groups to assess if at least one group mean is different from the others. If the F-statistic from ANOVA is significant, it indicates that at least one group differs, but further post-hoc tests are needed to identify specific differences.\n",
        "\n",
        "ANOVA relies on several key assumptions:\n",
        "\n",
        "Independence – The observations in each group must be independent of each other.\n",
        "Normality – The data within each group should be approximately normally distributed, especially for small sample sizes.\n",
        "Homogeneity of variances (Homoscedasticity) – The variance among groups should be roughly equal, which is tested using Levene’s test or Bartlett’s test.\n",
        "Violations of these assumptions can affect the reliability of ANOVA results, but in some cases, transformations or non-parametric alternatives like the Kruskal-Wallis test can be used."
      ],
      "metadata": {
        "id": "P-6k8Mon_3Ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What are the different types of ANOVA tests\n",
        "Ans. There are several types of ANOVA (Analysis of Variance) tests, each suited for different study designs and data structures.\n",
        "\n",
        "One-Way ANOVA – Used when comparing the means of three or more independent groups based on a single independent variable. It determines whether at least one group differs significantly.\n",
        "\n",
        "Two-Way ANOVA – Extends One-Way ANOVA by analyzing the effect of two independent variables simultaneously. It also examines if there is an interaction effect between the two factors.\n",
        "\n",
        "Repeated Measures ANOVA – Used when the same subjects are measured multiple times under different conditions or time points. It accounts for within-subject variability.\n",
        "\n",
        "Mixed-Design ANOVA – Combines repeated measures and between-subject designs, where one factor is measured within subjects and another between different groups."
      ],
      "metadata": {
        "id": "eABsWFga__hW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "Ans. The F-test is a statistical test used to compare variances between two groups or to assess the overall significance of a model in hypothesis testing. It is based on the F-distribution, which is right-skewed and depends on two degrees of freedom.\n",
        "\n",
        "In hypothesis testing, the F-test is commonly used in:\n",
        "\n",
        "ANOVA (Analysis of Variance) to check if multiple group means are significantly different by analyzing their variances.\n",
        "Variance comparison tests to determine if two populations have equal variances.\n",
        "Regression analysis to evaluate whether the independent variables significantly explain the variability in the dependent variable.\n",
        "The test statistic is calculated as the ratio of two variances:\n",
        "\n",
        "F = (Variance of group 1) / (Variance of group 2)\n",
        "If the computed F-value is greater than the critical value from the F-distribution table or if the P-value ≤ significance level (α), the null hypothesis (which assumes equality of variances or no significant effect) is rejected."
      ],
      "metadata": {
        "id": "OqcfrZ3cAG1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results\n"
      ],
      "metadata": {
        "id": "1TjIX9abATUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample_mean, pop_mean, pop_std, sample_size, alpha=0.05):\n",
        "    # Calculate the Z-score\n",
        "    z_score = (sample_mean - pop_mean) / (pop_std / (sample_size ** 0.5))\n",
        "\n",
        "    # Calculate the P-value (two-tailed test)\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpretation\n",
        "    print(f\"Z-score: {z_score:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population mean.\")\n",
        "\n",
        "# Example usage\n",
        "z_test(sample_mean=52, pop_mean=50, pop_std=10, sample_size=30)"
      ],
      "metadata": {
        "id": "mKEyPbAVAiv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How It Works:\n",
        "Computes the Z-score to measure how far the sample mean deviates from the population mean.\n",
        "Calculates the P-value for a two-tailed test.\n",
        "Compares the P-value to the significance level (α = 0.05 by default) to determine whether to reject or fail to reject the null hypothesis.\n",
        "Interpretation Example:\n",
        "If Z-score = 1.095 and P-value = 0.2739 (greater than 0.05), we fail to reject the null hypothesis, meaning there is no significant difference between the sample and population mean."
      ],
      "metadata": {
        "id": "V750ShwQAjps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python"
      ],
      "metadata": {
        "id": "XMKPHjdPAl_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate random sample data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_size = 30\n",
        "pop_mean = 50\n",
        "pop_std = 10\n",
        "\n",
        "# Generate a random sample from a normal distribution\n",
        "sample_data = np.random.normal(loc=pop_mean, scale=pop_std, size=sample_size)\n",
        "\n",
        "# Sample mean and standard deviation\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std = np.std(sample_data, ddof=1)  # Sample standard deviation\n",
        "\n",
        "# Perform hypothesis testing\n",
        "def hypothesis_test(sample_mean, pop_mean, sample_std, sample_size, alpha=0.05):\n",
        "    if sample_size >= 30:\n",
        "        # Z-test when sample size is large\n",
        "        z_score = (sample_mean - pop_mean) / (sample_std / np.sqrt(sample_size))\n",
        "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "        test_type = \"Z-test\"\n",
        "    else:\n",
        "        # T-test when sample size is small\n",
        "        t_score, p_value = stats.ttest_1samp(sample_data, pop_mean)\n",
        "        test_type = \"T-test\"\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Test Used: {test_type}\")\n",
        "    print(f\"Sample Mean: {sample_mean:.3f}\")\n",
        "    print(f\"Z-score/T-score: {z_score if test_type == 'Z-test' else t_score:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population mean.\")"
      ],
      "metadata": {
        "id": "tucEfWYBAzS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Used: Z-test\n",
        "Sample Mean: 48.568\n",
        "Z-score: -0.780\n",
        "P-value: 0.43529\n",
        "Fail to reject the null hypothesis: No significant difference between the sample and population mean."
      ],
      "metadata": {
        "id": "Bl8eAbnHA649"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean"
      ],
      "metadata": {
        "id": "E6ijV7QQA7h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def one_sample_z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    sample_size = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    # Calculate the Z-score\n",
        "    z_score = (sample_mean - pop_mean) / (pop_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Calculate the P-value for a two-tailed test\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample Mean: {sample_mean:.3f}\")\n",
        "    print(f\"Z-score: {z_score:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population mean.\")\n",
        "\n",
        "# Simulate random sample data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_size = 30\n",
        "pop_mean = 50\n",
        "pop_std = 10\n",
        "\n",
        "sample_data = np.random.normal(loc=pop_mean, scale=pop_std, size=sample_size)\n",
        "\n",
        "# Perform the one-sample Z-test\n",
        "one_sample_z_test(sample_data, pop_mean, pop_std)"
      ],
      "metadata": {
        "id": "iqeWVv3oA_bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot@"
      ],
      "metadata": {
        "id": "bTpkTAASFEC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def two_tailed_z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    sample_size = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - pop_mean) / (pop_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Calculate P-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Critical Z-value for two-tailed test\n",
        "    z_critical = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample Mean: {sample_mean:.3f}\")\n",
        "    print(f\"Z-score: {z_score:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "    print(f\"Critical Z-value: ±{z_critical:.3f}\")\n",
        "\n",
        "    if abs(z_score) > z_critical:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population mean.\")\n",
        "\n",
        "    # Visualization of the decision region\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = stats.norm.pdf(x, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, y, label=\"Standard Normal Distribution\")\n",
        "\n",
        "    # Shade critical rejection regions\n",
        "    plt.fill_between(x, y, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.5, label=\"Rejection Region\")\n",
        "    plt.axvline(z_score, color='blue', linestyle='dashed', label=f\"Z-score: {z_score:.3f}\")\n",
        "    plt.axvline(-z_critical, color='black', linestyle='dotted', label=f\"Critical Z: ±{z_critical:.3f}\")\n",
        "    plt.axvline(z_critical, color='black', linestyle='dotted')\n",
        "\n",
        "    plt.title(\"Two-Tailed Z-Test Decision Region\")\n",
        "    plt.xlabel(\"Z-score\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Simulate random sample data\n",
        "np.random.seed(42)\n",
        "sample_size = 30\n",
        "pop_mean = 50\n",
        "pop_std = 10\n",
        "\n",
        "sample_data = np.random.normal(loc=pop_mean, scale=pop_std, size=sample_size)\n",
        "\n",
        "# Perform the two-tailed Z-test\n",
        "two_tailed_z_test(sample_data, pop_mean, pop_std)"
      ],
      "metadata": {
        "id": "BCXlG7YtFQR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing"
      ],
      "metadata": {
        "id": "pQjHfvHlFQ7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_type1_type2_errors(pop_mean, pop_std, sample_size, alpha=0.05, effect_size=0.5):\n",
        "    \"\"\"\n",
        "    Visualizes Type 1 and Type 2 errors in hypothesis testing.\n",
        "\n",
        "    Parameters:\n",
        "    - pop_mean: Mean under the null hypothesis (H₀)\n",
        "    - pop_std: Standard deviation of the population\n",
        "    - sample_size: Sample size\n",
        "    - alpha: Significance level (default: 0.05)\n",
        "    - effect_size: Difference between null and alternative means (default: 0.5 SD)\n",
        "    \"\"\"\n",
        "\n",
        "    # Standard error\n",
        "    std_error = pop_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Critical Z-value for one-tailed test\n",
        "    z_critical = stats.norm.ppf(1 - alpha)\n",
        "\n",
        "    # Critical value (Threshold to reject H₀)\n",
        "    critical_value = pop_mean + z_critical * std_error\n",
        "\n",
        "    # Define alternative hypothesis mean (H₁ shifted by effect size)\n",
        "    alt_mean = pop_mean + effect_size * pop_std\n",
        "\n",
        "    # Generate x-values\n",
        "    x = np.linspace(pop_mean - 4 * std_error, alt_mean + 4 * std_error, 1000)\n",
        "\n",
        "    # PDF for H₀ and H₁ distributions\n",
        "    y_h0 = stats.norm.pdf(x, pop_mean, std_error)\n",
        "    y_h1 = stats.norm.pdf(x, alt_mean, std_error)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot distributions\n",
        "    plt.plot(x, y_h0, label=\"Null Hypothesis (H₀)\", color='blue')\n",
        "    plt.plot(x, y_h1, label=\"Alternative Hypothesis (H₁)\", color='green')\n",
        "\n",
        "    # Shade Type 1 Error region (False Positive)\n",
        "    plt.fill_between(x, y_h0, where=(x > critical_value), color='red', alpha=0.4, label=\"Type 1 Error (α)\")\n",
        "\n",
        "    # Shade Type 2 Error region (False Negative)\n",
        "    plt.fill_between(x, y_h1, where=(x < critical_value), color='purple', alpha=0.4, label=\"Type 2 Error (β)\")\n",
        "\n",
        "    # Add threshold line\n",
        "    plt.axvline(critical_value, color='black', linestyle='dashed', label=f\"Critical Value: {critical_value:.2f}\")\n",
        "\n",
        "    # Labels and legend\n",
        "    plt.title(\"Type 1 and Type 2 Errors in Hypothesis Testing\")\n",
        "    plt.xlabel(\"Test Statistic\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "visualize_type1_type2_errors(pop_mean=50, pop_std=10, sample_size=30, alpha=0.05, effect_size=0.5)"
      ],
      "metadata": {
        "id": "4lSO2SIMFfF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results\n"
      ],
      "metadata": {
        "id": "CobJ8V6xFh0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def independent_t_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs an independent two-sample T-test and interprets the results.\n",
        "\n",
        "    Parameters:\n",
        "    - sample1: First sample (list or numpy array)\n",
        "    - sample2: Second sample (list or numpy array)\n",
        "    - alpha: Significance level (default: 0.05)\n",
        "    \"\"\"\n",
        "    # Calculate the T-test\n",
        "    t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=False)  # Welch’s T-test\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample 1 Mean: {np.mean(sample1):.3f}\")\n",
        "    print(f\"Sample 2 Mean: {np.mean(sample2):.3f}\")\n",
        "    print(f\"T-statistic: {t_stat:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "\n",
        "    # Decision rule\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The means of the two groups are significantly different.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the two group means.\")\n",
        "\n",
        "# Simulate random sample data for two groups\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample1 = np.random.normal(loc=55, scale=10, size=30)  # Group 1: Mean 55, SD 10\n",
        "sample2 = np.random.normal(loc=50, scale=10, size=30)  # Group 2: Mean 50, SD 10\n",
        "\n",
        "# Perform the independent T-test\n",
        "independent_t_test(sample1, sample2)"
      ],
      "metadata": {
        "id": "nazL5sI3Fodk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a paired sample T-test using Python and visualize the comparison results"
      ],
      "metadata": {
        "id": "NwiBO7vrFx61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def paired_t_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a paired sample T-test and visualizes the results.\n",
        "\n",
        "    Parameters:\n",
        "    - sample1: First sample (before treatment)\n",
        "    - sample2: Second sample (after treatment)\n",
        "    - alpha: Significance level (default: 0.05)\n",
        "    \"\"\"\n",
        "    # Calculate the Paired T-test\n",
        "    t_stat, p_value = stats.ttest_rel(sample1, sample2)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Before Treatment Mean: {np.mean(sample1):.3f}\")\n",
        "    print(f\"After Treatment Mean: {np.mean(sample2):.3f}\")\n",
        "    print(f\"T-statistic: {t_stat:.3f}\")\n",
        "    print(f\"P-value: {p_value:.5f}\")\n",
        "\n",
        "    # Decision rule\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: There is a significant difference before and after treatment.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference before and after treatment.\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    # Scatter plot of paired values\n",
        "    plt.scatter(sample1, sample2, color='blue', alpha=0.7, label=\"Before vs After\")\n",
        "\n",
        "    # Line connecting paired values\n",
        "    for i in range(len(sample1)):\n",
        "        plt.plot([sample1[i], sample2[i]], [i, i], color='gray', alpha=0.5)\n",
        "\n",
        "    # Mean values\n",
        "    plt.axvline(np.mean(sample1), color='blue', linestyle='dashed', label=\"Mean Before\")\n",
        "    plt.axvline(np.mean(sample2), color='red', linestyle='dashed', label=\"Mean After\")\n",
        "\n",
        "    plt.xlabel(\"Measurement Value\")\n",
        "    plt.ylabel(\"Samples\")\n",
        "    plt.title(\"Paired Sample T-Test: Before vs After Treatment\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Simulate paired sample data (Before & After Treatment)\n",
        "np.random.seed(42)\n",
        "sample_size = 30\n",
        "before_treatment = np.random.normal(loc=55, scale=10, size=sample_size)  # Before treatment\n",
        "after_treatment = before_treatment + np.random.normal(loc=-2, scale=5, size=sample_size)  # After treatment (shifted mean)\n",
        "\n",
        "# Perform the paired T-test\n",
        "paired_t_test(before_treatment, after_treatment)"
      ],
      "metadata": {
        "id": "ZsQprOsvF1Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Simulate data and perform both Z-test and T-test, then compare the results using Python"
      ],
      "metadata": {
        "id": "JQsdh6HGGCOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def perform_tests(sample1, sample2, pop_std=None, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs both an independent Z-test and a T-test, then compares the results.\n",
        "\n",
        "    Parameters:\n",
        "    - sample1: First sample (numpy array)\n",
        "    - sample2: Second sample (numpy array)\n",
        "    - pop_std: Known population standard deviation (if available, used for Z-test)\n",
        "    - alpha: Significance level (default: 0.05)\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate sample statistics\n",
        "    mean1, mean2 = np.mean(sample1), np.mean(sample2)\n",
        "    n1, n2 = len(sample1), len(sample2)\n",
        "    std1, std2 = np.std(sample1, ddof=1), np.std(sample2, ddof=1)\n",
        "\n",
        "    print(f\"Sample 1 Mean: {mean1:.3f}, Std Dev: {std1:.3f}\")\n",
        "    print(f\"Sample 2 Mean: {mean2:.3f}, Std Dev: {std2:.3f}\")\n",
        "\n",
        "    # Perform Independent T-test (Welch’s T-test)\n",
        "    t_stat, t_p_value = stats.ttest_ind(sample1, sample2, equal_var=False)\n",
        "\n",
        "    # Perform Z-test if population standard deviation is known\n",
        "    if pop_std:\n",
        "        se = np.sqrt((pop_std ** 2 / n1) + (pop_std ** 2 / n2))\n",
        "        z_stat = (mean1 - mean2) / se\n",
        "        z_p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))  # Two-tailed Z-test\n",
        "    else:\n",
        "        z_stat, z_p_value = None, None  # Z-test cannot be performed without known population std\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n--- Hypothesis Testing Results ---\")\n",
        "    print(f\"T-test: T-statistic = {t_stat:.3f}, P-value = {t_p_value:.5f}\")\n",
        "    if z_stat is not None:\n",
        "        print(f\"Z-test: Z-statistic = {z_stat:.3f}, P-value = {z_p_value:.5f}\")\n",
        "\n",
        "    # Decision rule\n",
        "    if t_p_value < alpha:\n",
        "        print(\"T-test: Reject the null hypothesis (Significant difference between means).\")\n",
        "    else:\n",
        "        print(\"T-test: Fail to reject the null hypothesis (No significant difference).\")\n",
        "\n",
        "    if z_stat is not None:\n",
        "        if z_p_value < alpha:\n",
        "            print(\"Z-test: Reject the null hypothesis (Significant difference between means).\")\n",
        "        else:\n",
        "            print(\"Z-test: Fail to reject the null hypothesis (No significant difference).\")\n",
        "\n",
        "# Simulate data: Two groups with different means\n",
        "np.random.seed(42)\n",
        "sample_size = 30\n",
        "sample1 = np.random.normal(loc=55, scale=10, size=sample_size)  # Mean = 55, SD = 10\n",
        "sample2 = np.random.normal(loc=50, scale=10, size=sample_size)  # Mean = 50, SD = 10\n",
        "pop_std = 10  # Assume known population standard deviation for Z-test\n",
        "\n",
        "# Perform Z-test and T-test\n",
        "perform_tests(sample1, sample2, pop_std)"
      ],
      "metadata": {
        "id": "gPqyNuwNGFhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance"
      ],
      "metadata": {
        "id": "u2k-n0TLGSmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def confidence_interval(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: List or numpy array of sample data\n",
        "    - confidence: Confidence level (default is 95%)\n",
        "\n",
        "    Returns:\n",
        "    - Tuple: (Lower bound, Upper bound) of the confidence interval\n",
        "    \"\"\"\n",
        "    sample_size = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # Sample standard deviation (ddof=1 for unbiased estimate)\n",
        "\n",
        "    # Calculate the critical value (T-score for small samples, Z-score for large samples)\n",
        "    if sample_size >= 30:\n",
        "        critical_value = stats.norm.ppf((1 + confidence) / 2)  # Z-score\n",
        "    else:\n",
        "        critical_value = stats.t.ppf((1 + confidence) / 2, df=sample_size - 1)  # T-score\n",
        "\n",
        "    # Compute standard error\n",
        "    standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Compute margin of error\n",
        "    margin_of_error = critical_value * standard_error\n",
        "\n",
        "    # Compute confidence interval\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage: Simulate sample data and calculate confidence interval\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Mean = 50, SD = 10, Sample size = 30\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(sample_data, confidence=0.95)\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.3f}, {ci_upper:.3f})\")"
      ],
      "metadata": {
        "id": "pQv0T7EjGVNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data"
      ],
      "metadata": {
        "id": "JPMpaxfJGfls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def margin_of_error(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the margin of error for a given confidence level using sample data.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: List or numpy array of sample data\n",
        "    - confidence: Confidence level (default is 95%)\n",
        "\n",
        "    Returns:\n",
        "    - Margin of Error (float)\n",
        "    \"\"\"\n",
        "    sample_size = len(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # Sample standard deviation (unbiased estimate)\n",
        "\n",
        "    # Determine the critical value (Z-score for large samples, T-score for small samples)\n",
        "    if sample_size >= 30:\n",
        "        critical_value = stats.norm.ppf((1 + confidence) / 2)  # Z-score\n",
        "    else:\n",
        "        critical_value = stats.t.ppf((1 + confidence) / 2, df=sample_size - 1)  # T-score\n",
        "\n",
        "    # Compute standard error\n",
        "    standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Compute margin of error\n",
        "    moe = critical_value * standard_error\n",
        "    return moe\n",
        "\n",
        "# Example usage: Simulate sample data and calculate margin of error\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=30)  # Mean = 50, SD = 10, Sample size = 30\n",
        "\n",
        "moe_95 = margin_of_error(sample_data, confidence=0.95)\n",
        "print(f\"95% Margin of Error: {moe_95:.3f}\")"
      ],
      "metadata": {
        "id": "bC-Ts1m8GfGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process"
      ],
      "metadata": {
        "id": "dnRR02USGqsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem(prior, likelihood, evidence):\n",
        "    \"\"\"\n",
        "    Computes the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - prior: P(H) -> Initial belief about hypothesis\n",
        "    - likelihood: P(D | H) -> Probability of data given hypothesis\n",
        "    - evidence: P(D) -> Total probability of observing the data\n",
        "\n",
        "    Returns:\n",
        "    - Posterior probability P(H | D)\n",
        "    \"\"\"\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Example: Disease Testing Scenario\n",
        "# H = \"Person has disease\"\n",
        "# D = \"Test is positive\"\n",
        "prior = 0.01       # P(H) -> Prior probability of having the disease (1% of people have it)\n",
        "likelihood = 0.95  # P(D | H) -> Test correctly identifies disease 95% of the time\n",
        "false_positive = 0.05  # P(D | ¬H) -> Test incorrectly identifies healthy as positive 5% of the time\n",
        "not_hypothesis = 1 - prior  # Probability of not having the disease\n",
        "\n",
        "# P(D) = P(D | H) * P(H) + P(D | ¬H) * P(¬H) (Total probability of a positive test)\n",
        "evidence = (likelihood * prior) + (false_positive * not_hypothesis)\n",
        "\n",
        "# Compute posterior probability P(H | D)\n",
        "posterior = bayes_theorem(prior, likelihood, evidence)\n",
        "print(f\"Updated probability of having the disease given a positive test: {posterior:.4f}\")"
      ],
      "metadata": {
        "id": "-pBfKjF1G9Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform a Chi-square test for independence between two categorical variables in PythonD"
      ],
      "metadata": {
        "id": "dPwEXQtvG-dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample dataset: Survey of customers (Gender vs. Product Preference)\n",
        "data = np.array([[30, 10],   # Male (Product A, Product B)\n",
        "                 [20, 40]])  # Female (Product A, Product B)\n",
        "\n",
        "# Convert to a Pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Product A\", \"Product B\"], index=[\"Male\", \"Female\"])\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(df)\n",
        "\n",
        "# Display results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(pd.DataFrame(expected, columns=df.columns, index=df.index))\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis - The variables are dependent.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis - No significant association.\")"
      ],
      "metadata": {
        "id": "kzr_ybZdHBrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data\n"
      ],
      "metadata": {
        "id": "HOLvxpcxHOM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculates expected frequencies for a Chi-square test.\n",
        "\n",
        "    Parameters:\n",
        "    - observed: 2D numpy array or list representing the contingency table\n",
        "\n",
        "    Returns:\n",
        "    - Expected frequency table as a NumPy array\n",
        "    \"\"\"\n",
        "    observed = np.array(observed)\n",
        "\n",
        "    # Compute row totals, column totals, and grand total\n",
        "    row_totals = observed.sum(axis=1, keepdims=True)\n",
        "    col_totals = observed.sum(axis=0, keepdims=True)\n",
        "    grand_total = observed.sum()\n",
        "\n",
        "    # Calculate expected frequencies\n",
        "    expected = (row_totals @ col_totals) / grand_total  # Matrix multiplication\n",
        "    return expected\n",
        "\n",
        "# Example observed data: Gender vs. Product Preference\n",
        "observed_data = np.array([[30, 10],  # Males (Product A, Product B)\n",
        "                          [20, 40]]) # Females (Product A, Product B)\n",
        "\n",
        "# Compute expected frequencies\n",
        "expected_frequencies = calculate_expected_frequencies(observed_data)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "df_expected = pd.DataFrame(expected_frequencies, columns=[\"Product A\", \"Product B\"], index=[\"Male\", \"Female\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Expected Frequencies:\")\n",
        "print(df_expected)"
      ],
      "metadata": {
        "id": "cK8C77RZHNj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution"
      ],
      "metadata": {
        "id": "Sqc0z9pyHf3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed data: Counts of items in different categories\n",
        "observed = np.array([50, 30, 20])  # Example: observed frequencies\n",
        "\n",
        "# Expected data: Assume equal distribution or a known expected proportion\n",
        "expected = np.array([40, 40, 20])  # Hypothetical expected frequencies\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Display results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis - Observed data does not fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis - Observed data fits the expected distribution.\")"
      ],
      "metadata": {
        "id": "UhiAgrV2HxAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics"
      ],
      "metadata": {
        "id": "EVg1cq9JHxpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate Chi-square distribution for different degrees of freedom\n",
        "df_values = [2, 4, 6, 10]  # Different degrees of freedom\n",
        "x = np.linspace(0, 30, 500)  # Range of x values\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot Chi-square distributions for different degrees of freedom\n",
        "for df in df_values:\n",
        "    y = stats.chi2.pdf(x, df)  # Probability Density Function (PDF)\n",
        "    plt.plot(x, y, label=f'df = {df}')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Chi-square Value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.title(\"Chi-square Distribution for Different Degrees of Freedom\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5JUQuF3UH1Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Implement an F-test using Python to compare the variances of two random samplesD"
      ],
      "metadata": {
        "id": "RCzYpEtiIBWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate two random samples\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10, Size=30\n",
        "sample2 = np.random.normal(loc=50, scale=15, size=30)  # Mean=50, Std=15, Size=30\n",
        "\n",
        "# Calculate sample variances\n",
        "var1 = np.var(sample1, ddof=1)  # Sample variance (unbiased)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Compute F-statistic\n",
        "F_statistic = var1 / var2 if var1 > var2 else var2 / var1  # Ensure F >= 1\n",
        "\n",
        "# Calculate p-value\n",
        "df1, df2 = len(sample1) - 1, len(sample2) - 1  # Degrees of freedom\n",
        "p_value = 2 * (1 - stats.f.cdf(F_statistic, df1, df2))  # Two-tailed test\n",
        "\n",
        "# Display results\n",
        "print(f\"Sample 1 Variance: {var1:.4f}\")\n",
        "print(f\"Sample 2 Variance: {var2:.4f}\")\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis - Variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis - No significant difference in variances.\")"
      ],
      "metadata": {
        "id": "QGFnk1FUINaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "interpret the results"
      ],
      "metadata": {
        "id": "bSIjjX4wIZXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate sample data for three groups (e.g., different study methods)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10, Size=30\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)  # Mean=55, Std=10, Size=30\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)  # Mean=60, Std=10, Size=30\n",
        "\n",
        "# Perform One-Way ANOVA\n",
        "F_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Display results\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis - At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis - No significant difference between group means.\")"
      ],
      "metadata": {
        "id": "H33Wu9LEIdP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results"
      ],
      "metadata": {
        "id": "2v19g6wcImCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Generate sample data for three groups (e.g., different treatments)\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)  # Mean=55, Std=10\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)  # Mean=60, Std=10\n",
        "\n",
        "# Perform One-Way ANOVA\n",
        "F_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "data = pd.DataFrame({\n",
        "    'Value': np.concatenate([group1, group2, group3]),\n",
        "    'Group': (['Group 1'] * len(group1)) + (['Group 2'] * len(group2)) + (['Group 3'] * len(group3))\n",
        "})\n",
        "\n",
        "# Plot the results using a boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Group', y='Value', data=data, palette='Set2')\n",
        "plt.title(\"One-Way ANOVA: Comparing Group Means\")\n",
        "plt.xlabel(\"Groups\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Display ANOVA results\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis - At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis - No significant difference between group means.\")"
      ],
      "metadata": {
        "id": "lk8DkTD-IpO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA"
      ],
      "metadata": {
        "id": "ziqF4JiTI0Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    \"\"\"\n",
        "    Checks ANOVA assumptions: normality (Shapiro-Wilk test),\n",
        "    equal variance (Levene’s test), and visualizes distributions.\n",
        "\n",
        "    Parameters:\n",
        "    *groups: Arrays representing different sample groups\n",
        "\n",
        "    Returns:\n",
        "    None - Prints results and plots distributions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Normality Check (Shapiro-Wilk Test)\n",
        "    print(\"\\n--- Normality Test (Shapiro-Wilk) ---\")\n",
        "    for i, group in enumerate(groups, 1):\n",
        "        stat, p_value = stats.shapiro(group)\n",
        "        print(f\"Group {i}: W-statistic={stat:.4f}, P-value={p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"  -> Group {i} is NOT normally distributed.\")\n",
        "        else:\n",
        "            print(f\"  -> Group {i} is normally distributed.\")\n",
        "\n",
        "    # Equal Variance Check (Levene’s Test)\n",
        "    print(\"\\n--- Homogeneity of Variance Test (Levene's Test) ---\")\n",
        "    stat, p_value = stats.levene(*groups)\n",
        "    print(f\"Levene's Test Statistic={stat:.4f}, P-value={p_value:.4f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"  -> Variances are NOT equal (violates assumption).\")\n",
        "    else:\n",
        "        print(\"  -> Variances are equal (assumption holds).\")\n",
        "\n",
        "    # Visualization: Histograms & Boxplots\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Histogram for Normality Check\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for group, label in zip(groups, [f'Group {i+1}' for i in range(len(groups))]):\n",
        "        sns.histplot(group, kde=True, label=label, alpha=0.6)\n",
        "    plt.legend()\n",
        "    plt.title(\"Histogram: Normality Check\")\n",
        "\n",
        "    # Boxplot for Variance Check\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(data=groups)\n",
        "    plt.xticks(ticks=range(len(groups)), labels=[f'Group {i+1}' for i in range(len(groups))])\n",
        "    plt.title(\"Boxplot: Variance Comparison\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QxhqIcsWI6hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the\n",
        "results"
      ],
      "metadata": {
        "id": "w1P8N17qJKnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulating Data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Factors: Study Method (Online vs. Offline), Study Duration (Short vs. Long)\n",
        "study_method = np.repeat(['Online', 'Offline'], 20)\n",
        "study_duration = ['Short', 'Long'] * 20\n",
        "\n",
        "# Simulated exam scores (dependent variable) with some random variation\n",
        "scores = (np.random.normal(70, 5, 40) +\n",
        "          (np.array(study_method) == 'Offline') * 5 +  # Offline methods increase score\n",
        "          (np.array(study_duration) == 'Long') * 3)  # Long study duration increases score\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'Study_Method': study_method, 'Study_Duration': study_duration, 'Scores': scores})\n",
        "\n",
        "# Performing Two-Way ANOVA\n",
        "model = ols('Scores ~ Study_Method + Study_Duration + Study_Method:Study_Duration', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Display Results\n",
        "print(\"Two-Way ANOVA Results:\\n\")\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: Boxplot for Study Method and Study Duration\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x='Study_Method', y='Scores', hue='Study_Duration', data=df, palette=\"Set2\")\n",
        "plt.title(\"Two-Way ANOVA: Interaction of Study Method & Duration on Exam Scores\")\n",
        "plt.xlabel(\"Study Method\")\n",
        "plt.ylabel(\"Exam Scores\")\n",
        "plt.legend(title=\"Study Duration\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FbqRhx3JN3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing"
      ],
      "metadata": {
        "id": "VCF38Lb0JcO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_f_distribution(df1, df2, x_max=5):\n",
        "    \"\"\"\n",
        "    Plots the F-distribution for given degrees of freedom.\n",
        "\n",
        "    Parameters:\n",
        "    df1 (int): Degrees of freedom for numerator\n",
        "    df2 (int): Degrees of freedom for denominator\n",
        "    x_max (float): Maximum x-axis value for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.linspace(0, x_max, 1000)\n",
        "    y = stats.f.pdf(x, df1, df2)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})', color='blue')\n",
        "\n",
        "    # Critical region (Right-tailed test, 5% significance level)\n",
        "    f_critical = stats.f.ppf(0.95, df1, df2)\n",
        "    plt.axvline(f_critical, color='red', linestyle='dashed', label=f'Critical Value (α=0.05): {f_critical:.2f}')\n",
        "\n",
        "    plt.fill_between(x, y, where=(x >= f_critical), color='red', alpha=0.3, label=\"Rejection Region\")\n",
        "\n",
        "    plt.title(\"F-Distribution and Critical Region\")\n",
        "    plt.xlabel(\"F-value\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Example: Plot F-distribution for df1=5, df2=10\n",
        "plot_f_distribution(df1=5, df2=10)"
      ],
      "metadata": {
        "id": "mOZ3N7yfJ0zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.  Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means"
      ],
      "metadata": {
        "id": "X5bRJ6xIKX4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulating Data: Exam Scores for 3 Teaching Methods\n",
        "np.random.seed(42)\n",
        "group_A = np.random.normal(loc=70, scale=5, size=30)  # Mean=70, SD=5\n",
        "group_B = np.random.normal(loc=75, scale=5, size=30)  # Mean=75, SD=5\n",
        "group_C = np.random.normal(loc=80, scale=5, size=30)  # Mean=80, SD=5\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame({'Scores': np.concatenate([group_A, group_B, group_C]),\n",
        "                   'Method': ['A'] * 30 + ['B'] * 30 + ['C'] * 30})\n",
        "\n",
        "# One-Way ANOVA\n",
        "model = ols('Scores ~ Method', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Display Results\n",
        "print(\"One-Way ANOVA Results:\\n\")\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='Method', y='Scores', data=df, palette=\"Set2\")\n",
        "plt.title(\"One-Way ANOVA: Comparison of Teaching Methods\")\n",
        "plt.xlabel(\"Teaching Method\")\n",
        "plt.ylabel(\"Exam Scores\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQAKv8YWKcP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means"
      ],
      "metadata": {
        "id": "ULdJwD0wKjl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate Data from a Normal Distribution\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=75, scale=10, size=30)  # Mean=75, SD=10, Sample Size=30\n",
        "sample2 = np.random.normal(loc=78, scale=10, size=30)  # Mean=78, SD=10, Sample Size=30\n",
        "\n",
        "# Step 2: Perform an Independent T-test\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=True)  # Assuming equal variance\n",
        "\n",
        "# Display Results\n",
        "print(\"Hypothesis Testing Results:\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 3: Interpretation\n",
        "alpha = 0.05  # Significance Level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. The means are significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant difference in means.\")"
      ],
      "metadata": {
        "id": "toA0QH2_LtJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results"
      ],
      "metadata": {
        "id": "spNBDILJLtzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate Sample Data (Assume Normal Distribution)\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=50, scale=8, size=30)  # Mean=50, SD=8, Sample Size=30\n",
        "\n",
        "# Step 2: Define Parameters\n",
        "sample_size = len(sample)\n",
        "sample_variance = np.var(sample, ddof=1)  # Unbiased Sample Variance (ddof=1)\n",
        "pop_variance = 64  # Hypothesized population variance (SD^2 = 8^2)\n",
        "\n",
        "# Step 3: Compute Chi-Square Test Statistic\n",
        "chi_square_stat = (sample_size - 1) * sample_variance / pop_variance\n",
        "\n",
        "# Step 4: Compute P-value (Two-tailed test)\n",
        "alpha = 0.05  # Significance Level\n",
        "p_value = 2 * min(stats.chi2.cdf(chi_square_stat, df=sample_size-1),\n",
        "                   1 - stats.chi2.cdf(chi_square_stat, df=sample_size-1))\n",
        "\n",
        "# Step 5: Display Results\n",
        "print(f\"Sample Variance: {sample_variance:.2f}\")\n",
        "print(f\"Chi-Square Statistic: {chi_square_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. The population variance is significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant difference in variance.\")"
      ],
      "metadata": {
        "id": "kksmZjJWL8P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups"
      ],
      "metadata": {
        "id": "-6dLHf0SL9Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Define the data (Number of successes and sample sizes)\n",
        "success_1, n1 = 50, 200  # Group 1: 50 successes in 200 trials\n",
        "success_2, n2 = 30, 180  # Group 2: 30 successes in 180 trials\n",
        "\n",
        "# Step 2: Calculate Proportions\n",
        "p1 = success_1 / n1\n",
        "p2 = success_2 / n2\n",
        "\n",
        "# Step 3: Calculate Pooled Proportion\n",
        "p = (success_1 + success_2) / (n1 + n2)\n",
        "\n",
        "# Step 4: Compute Z-Statistic\n",
        "z_stat = (p1 - p2) / np.sqrt(p * (1 - p) * (1/n1 + 1/n2))\n",
        "\n",
        "# Step 5: Compute P-value (Two-tailed test)\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "# Step 6: Display Results\n",
        "print(f\"Proportion 1: {p1:.4f}\")\n",
        "print(f\"Proportion 2: {p2:.4f}\")\n",
        "print(f\"Z-Statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 7: Interpretation\n",
        "alpha = 0.05  # Significance Level\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant difference in proportions.\")"
      ],
      "metadata": {
        "id": "OZgaBIJvMA-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Implement an F-test for comparing the variances of two datasets, then interpret and visualize the resultsD\n"
      ],
      "metadata": {
        "id": "g2LE9C8xMTOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate Two Random Datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, SD=10, Size=30\n",
        "data2 = np.random.normal(loc=50, scale=15, size=30)  # Mean=50, SD=15, Size=30\n",
        "\n",
        "# Step 2: Compute Sample Variances\n",
        "var1 = np.var(data1, ddof=1)  # Unbiased Variance (ddof=1)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "\n",
        "# Step 3: Compute F-Statistic\n",
        "if var1 > var2:  # Ensure F > 1\n",
        "    F_stat = var1 / var2\n",
        "    df1, df2 = len(data1) - 1, len(data2) - 1\n",
        "else:\n",
        "    F_stat = var2 / var1\n",
        "    df1, df2 = len(data2) - 1, len(data1) - 1\n",
        "\n",
        "# Step 4: Compute P-value (One-tailed test)\n",
        "p_value = 1 - stats.f.cdf(F_stat, df1, df2)\n",
        "\n",
        "# Step 5: Display Results\n",
        "print(f\"Variance 1: {var1:.4f}\")\n",
        "print(f\"Variance 2: {var2:.4f}\")\n",
        "print(f\"F-Statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. The variances are not significantly different.\")\n",
        "\n",
        "# Step 6: Visualization - Histograms of Both Datasets\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(data1, bins=10, alpha=0.6, color='blue', label='Dataset 1')\n",
        "plt.hist(data2, bins=10, alpha=0.6, color='red', label='Dataset 2')\n",
        "plt.axvline(np.mean(data1), color='blue', linestyle='dashed', linewidth=2)\n",
        "plt.axvline(np.mean(data2), color='red', linestyle='dashed', linewidth=2)\n",
        "plt.legend()\n",
        "plt.title(\"Comparison of Two Datasets\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wljE7H9mMn5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results."
      ],
      "metadata": {
        "id": "rfsqoP7SMpCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate Observed Data (e.g., customer preferences for 5 product categories)\n",
        "np.random.seed(42)\n",
        "observed = np.random.randint(40, 100, size=5)  # Random observed frequencies\n",
        "\n",
        "# Step 2: Define Expected Distribution (Assume equal preference)\n",
        "expected = np.full(len(observed), np.mean(observed))\n",
        "\n",
        "# Step 3: Perform Chi-Square Goodness of Fit Test\n",
        "chi_square_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Display Results\n",
        "print(f\"Observed Frequencies: {observed}\")\n",
        "print(f\"Expected Frequencies: {expected.round(2)}\")\n",
        "print(f\"Chi-Square Statistic: {chi_square_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. The observed distribution is significantly different from expected.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. The observed distribution matches the expected distribution.\")\n",
        "\n",
        "# Step 5: Visualization\n",
        "categories = [f\"Category {i+1}\" for i in range(len(observed))]\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(categories, observed, color='blue', alpha=0.6, label=\"Observed\")\n",
        "plt.bar(categories, expected, color='red', alpha=0.6, label=\"Expected\")\n",
        "plt.xlabel(\"Categories\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Chi-Square Goodness of Fit Test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SddbdM-QMsM3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}